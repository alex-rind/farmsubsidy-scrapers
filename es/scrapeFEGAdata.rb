#!/usr/bin/env ruby
# encoding: utf-8
require 'fileutils'
require 'mechanize'
require 'csv'
# To correctly transform the case of special spanish caracters
require 'unicode_utils'

#Clean cells from the scraped table
#  Remove spaces and uppercase texts
#  Remove thousand separators and use . as the decimal point
def clean (c,i)
  if (i == 0)
    return c.text.gsub('.','').to_i  
  elsif (i > 0 && i < 4)
    return c.text.empty? ? nil : UnicodeUtils.downcase(c.text.strip, :es)
  else 
    return c.text.gsub('.','').gsub(',','.').to_f  
  end
end

#Process obtained html page
def extract_data (page)
  #Get the nokogiri parsed document
  doc = page.parser
  #Data is inside the second table, can not use css because it is not customized
  rows = doc.xpath("//table[2]/tbody/tr")
  rows.each do |row|
    cells = row.css("td")
    row_data = cells.map.with_index{|c,i| clean(c,i)}[0..6]
    save_csv_data(row_data)
  end
end

#Create one line per subsidy type if found
def save_csv_data (a)
  geo1 = a[3] ? "ES" : nil
  
  #EAGF DIRECT PAYMENTS
  if (a[4] && a[4] > 0)
    amount = a[4]
    type = "ES1"
    data = [$id,a[1..3],geo1,type,YEAR,amount,CURRENCY].flatten!
    $output_file.puts CSV::generate_line(data,:encoding => 'utf-8')
    $id += 1
  end
  #EAGF OTHER PAYMENTS
  if a[5] && a[5] > 0
    amount = a[5]
    type = "ES2"
    data = [$id,a[1..3],geo1,type,YEAR,amount,CURRENCY].flatten!
    $output_file.puts CSV::generate_line(data,:encoding => 'utf-8')
    $id += 1
  end
  #EAFRD PAYMENTS
  if a[6] && a[6] > 0
    amount = a[6]
    type = "ES3"
    data = [$id,a[1..3],geo1,type,YEAR,amount,CURRENCY].flatten!
    $output_file.puts CSV::generate_line(data,:encoding => 'utf-8')
    $id += 1
  end
end

#Create the folders where the data and logs will be stored
OUTPUT_SUBDIR = 'data'
LOG_SUBDIR = 'logs'
FileUtils.makedirs(LOG_SUBDIR)
FileUtils.makedirs(OUTPUT_SUBDIR)
CURRENCY = "EUR"
#Get the desired scrape year from arguments
YEAR = ARGV[0]
#Create an id that is unique for each payment
#  We can collect up to 10 million payments per year
$id = YEAR.to_i * 10000000 + 1

#To complete relative paths
HOME_URL = 'https://www.sede.fega.gob.es'
PREFFIX_URL = '/pwffgt/fgp_consultas_bene_tridion.mostrar_resultado'\
              '?w_cod_prov=99&w_cod_muni=00&pRegPag=1000&w_ordenar=3'
#Headers for the output file
HEADERS = ["id","name","geo2","geo3","geo1","type","year","amount","currency"]
          
#Extract script name
$0 =~ /^.*\/(.*)\.rb/
if $1.nil?
  return
else
  script_name = $1
end

#Create the log and output files
log_file = File.open("#{LOG_SUBDIR}/#{YEAR}#{script_name}.log", 'w')
$output_file = File.open("#{OUTPUT_SUBDIR}/#{YEAR}#{script_name}.csv", 'w')
#Write the header to the output file
$output_file.puts CSV::generate_line(HEADERS,:encoding => 'utf-8')

#Instantiate the mechanize object
agent = Mechanize.new

# Ignore SSL verification since we are only interested on scraping the site
agent.agent.http.verify_mode = OpenSSL::SSL::VERIFY_NONE

#Get the number of pages 
url = "#{HOME_URL}#{PREFFIX_URL}&w_ejercicio=#{YEAR}&pNumeroPag=1"
begin
  page = agent.get(url)
rescue Mechanize::ResponseCodeError => the_error
  log_file.puts("#{url}: Got a bad status code #{the_error.response_code}")
  return
end

puts "processing initial page"
#Get the nokogiri parsed document
doc = page.parser

#Get the number of pages dynamically generated by a embedded script
script_numpages = doc.css("script").last.text
script_numpages =~ /vNumPaginas\s+=\"(\d+)\";/
if $1.nil?
  log_file.puts("#{url}: Did not find the number of pages inside the last script")
  return
else
  numpages = $1.to_i
end
extract_data(page)

#Loop through the rest of the pages
for i in 2..numpages
  url = "#{HOME_URL}#{PREFFIX_URL}&w_ejercicio=#{YEAR}&pNumeroPag=#{i}"
  begin
    #puts url
    page = agent.get(url)
  rescue Mechanize::ResponseCodeError => the_error
    log_file.puts("#{url}: Got a bad status code #{the_error.response_code}")
    return
  end
  puts "processing page: #{i}"
  extract_data(page)
  # Give the remote site a break
  sleep(1)
end
$output_file.close
log_file.close


